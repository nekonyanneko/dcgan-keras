{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.core import Flatten, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 30\n",
    "PNG_CREATE = 20\n",
    "N_CLASS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 偽物を作る生成機\n",
    "def auto_encoder_generator_model():\n",
    "    model = Sequential()\n",
    "    # encoder\n",
    "    model.add(Conv2D(16, (3, 3), padding='same', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "    model.add(Conv2D(8, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "    model.add(Conv2D(8, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "    # decoder\n",
    "    model.add(Conv2D(8, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2D(8, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2D(16, (3, 3), padding='same'))\n",
    "    #model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2D(1, (3, 3), padding='same'))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    print('*** Auto encoder generator model ***')\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 偽物を検知する発見機\n",
    "def discriminator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (5, 5), padding='same', input_shape=(28, 28, 1)))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Conv2D(128, (5, 5), subsample=(2, 2))) # subsampleでダウンサンプリング\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(N_CLASS)) \n",
    "    model.add(Activation('sigmoid'))\n",
    "    print('*** discriminator model ***')\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_containing_discriminator(g, d):\n",
    "    model = Sequential()\n",
    "    model.add(g)\n",
    "    d.trainable = False\n",
    "    model.add(d)\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_images(generated_images):\n",
    "    num = generated_images.shape[0]\n",
    "    width = int(math.sqrt(num))\n",
    "    height = int(math.ceil(float(num)/width))\n",
    "    shape = generated_images.shape[1:3]\n",
    "    image = np.zeros((height*shape[0], width*shape[1]),\n",
    "                     dtype=generated_images.dtype)\n",
    "    for index, img in enumerate(generated_images):\n",
    "        i = int(index/width)\n",
    "        j = index % width\n",
    "        image[ i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1] ] = img[:, :, 0]\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(BATCH_SIZE):\n",
    "    ####\n",
    "    # Dataの読み込み\n",
    "    ####\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "    print (\"データのサイズ\")\n",
    "    print (\"X_train: %s, y_train:%s\" % (X_train.shape, y_train.shape))\n",
    "    print (\"X_test:  %s, y_test: %s\" % (X_test.shape, y_test.shape))\n",
    "    X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "    X_train = X_train[:, :, :, None] # channelは使用しない為None設定\n",
    "    X_test  = X_test [:, :, :, None] # channelは使用しない為None設定\n",
    "    \n",
    "    def create_label_data(in_y_data):\n",
    "        out_data = []\n",
    "        for index, data in enumerate(in_y_data):\n",
    "            if data == 0:\n",
    "                out_data.append([1,0,0,0,0,0,0,0,0,0])\n",
    "            elif data == 1:\n",
    "                out_data.append([0,1,0,0,0,0,0,0,0,0])\n",
    "            elif data == 2:\n",
    "                out_data.append([0,0,1,0,0,0,0,0,0,0])\n",
    "            elif data == 3:\n",
    "                out_data.append([0,0,0,1,0,0,0,0,0,0])\n",
    "            elif data == 4:\n",
    "                out_data.append([0,0,0,0,1,0,0,0,0,0])\n",
    "            elif data == 5:\n",
    "                out_data.append([0,0,0,0,0,1,0,0,0,0])\n",
    "            elif data == 6:\n",
    "                out_data.append([0,0,0,0,0,0,1,0,0,0])\n",
    "            elif data == 7:\n",
    "                out_data.append([0,0,0,0,0,0,0,1,0,0])\n",
    "            elif data == 8:\n",
    "                out_data.append([0,0,0,0,0,0,0,0,1,0])\n",
    "            else:\n",
    "                out_data.append([0,0,0,0,0,0,0,0,0,1])\n",
    "        return np.array(out_data)\n",
    "    \n",
    "    # yのデータを多次元化\n",
    "    ylabel_train = create_label_data(y_train)\n",
    "    ylabel_test = create_label_data(y_test)\n",
    "    \n",
    "    # generatorで生成した画像について間違えさせたいラベルを生成（ターゲットは適当）\n",
    "    def create_target_data(in_ylabel_data):\n",
    "        out_data = []\n",
    "        for index, data in enumerate(in_ylabel_data):\n",
    "            if data[0] == 1:\n",
    "                # 0を1と間違えさせるようにデータを生成する\n",
    "                out_data.append([0,1,0,0,0,0,0,0,0,0])\n",
    "            elif data[1] == 1:\n",
    "                out_data.append([0,0,1,0,0,0,0,0,0,0])\n",
    "            elif data[2] == 1:\n",
    "                out_data.append([0,0,0,1,0,0,0,0,0,0])\n",
    "            elif data[3] == 1:\n",
    "                out_data.append([0,0,0,0,1,0,0,0,0,0])\n",
    "            elif data[4] == 1:\n",
    "                out_data.append([0,0,0,0,0,1,0,0,0,0])\n",
    "            elif data[5] == 1:\n",
    "                out_data.append([0,0,0,0,0,0,1,0,0,0])\n",
    "            elif data[6] == 1:\n",
    "                out_data.append([0,0,0,0,0,0,0,1,0,0])\n",
    "            elif data[7] == 1:\n",
    "                out_data.append([0,0,0,0,0,0,0,0,1,0])\n",
    "            elif data[8] == 1:\n",
    "                out_data.append([0,0,0,0,0,0,0,0,0,1])\n",
    "            else:\n",
    "                out_data.append([1,0,0,0,0,0,0,0,0,0])\n",
    "        return np.array(out_data)\n",
    "    \n",
    "    # target用データを生成\n",
    "    target_ylabel_train = create_target_data(ylabel_train)\n",
    "    target_ylabel_test = create_target_data(ylabel_test)\n",
    "\n",
    "    ####\n",
    "    # モデルの準備\n",
    "    ####\n",
    "    # discriminatorとgeneratorの作成\n",
    "    d = discriminator_model()\n",
    "    g = auto_encoder_generator_model()\n",
    "    \n",
    "    # discriminatorとgeneratorのCONCATをしてAdversarial Training\n",
    "    d_on_g = generator_containing_discriminator(g, d) # この内部では d.trainable=False となっているためdは学習しない\n",
    "    \n",
    "    # discriminatorとgenerator,Adversarial Trainingの最適化手法としてAdamを利用する\n",
    "    d_optim = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    g_optim = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0) # \n",
    "    d_on_g_optim = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    g.compile(loss='binary_crossentropy', optimizer=g_optim)\n",
    "    d_on_g.compile(loss='binary_crossentropy', optimizer=d_on_g_optim)\n",
    "    d.trainable = True # Discriminatorの学習をONにしておく\n",
    "    d.compile(loss='binary_crossentropy', optimizer=d_optim)\n",
    "\n",
    "    ####\n",
    "    # epoch数分のループ\n",
    "    ####\n",
    "    for epoch in range(EPOCH):\n",
    "        print(\"Epoch is\", epoch)\n",
    "        print(\"Number of batches\", int( X_train.shape[0] / BATCH_SIZE ))\n",
    "\n",
    "        ####\n",
    "        # batchのループ\n",
    "        ####\n",
    "        for index in range(int( X_train.shape[0] / BATCH_SIZE )):\n",
    "            image_batch = X_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE] # 学習画像をBatch分、取得する\n",
    "            ylabel_train_batch = ylabel_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
    "            target_ylabel_train_batch = target_ylabel_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
    "            \n",
    "            generated_images = g.predict(image_batch, verbose=0) # Auto encoder でAdversarial画像データを生成\n",
    "            \n",
    "            ####\n",
    "            # 指定回数の度に、状況をPNG画像で確認\n",
    "            ####\n",
    "            if index % PNG_CREATE == 0:\n",
    "                image = combine_images(generated_images)\n",
    "                image = image*127.5+127.5\n",
    "                print('*** Generate Image by Auto encoder ***')\n",
    "                Image.fromarray(image.astype(np.uint8)).save(str(epoch)+\"_\"+str(index)+\".png\")\n",
    "\n",
    "            ####\n",
    "            # 評価\n",
    "            ####\n",
    "            print (\"image_batch: %s, generated_images:%s\" % (image_batch.shape, generated_images.shape))\n",
    "            print (\"ylabel_train_batch: %s, target_ylabel_train_batch:%s\" % (ylabel_train_batch.shape, target_ylabel_train_batch.shape))\n",
    "            X = np.concatenate((image_batch, generated_images)) # 学習画像と生成画像のCONCAT\n",
    "            y = np.concatenate((ylabel_train_batch, target_ylabel_train_batch)) # 正解ラベルと生成画像に付与するtargetラベルのCONCAT\n",
    "            \n",
    "            # discriminatorで評価(入力画像に対して付与されたラベルを正しく検出できるかどうか)\n",
    "            d_loss = d.train_on_batch(X, y)\n",
    "            print(\"batch %d D_loss : %f\" % (index, d_loss))\n",
    "            \n",
    "            # generatorを評価(Adversarial画像が生成できているかどうか)\n",
    "            d.trainable = False # discriminatorの学習をOFFにする\n",
    "            g_loss = d_on_g.train_on_batch(image_batch, ylabel_train)\n",
    "            d.trainable = True # discriminatorの学習をONにする\n",
    "            print(\"batch %d G_loss : %f\" % (index, g_loss))\n",
    "    \n",
    "            # 適度にモデルのパラメータを出力する\n",
    "            if index % 10 == 9:\n",
    "                g.save_weights('generator', True)\n",
    "                d.save_weights('discriminator', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データのサイズ\n",
      "X_train: (60000, 28, 28), y_train:(60000,)\n",
      "X_test:  (10000, 28, 28), y_test: (10000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (5, 5), strides=(2, 2))`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** discriminator model ***\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 64)        1664      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 128)       204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              18875392  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                10250     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 19,092,234\n",
      "Trainable params: 19,092,234\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "*** Auto encoder generator model ***\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 8)         1160      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 14, 14, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 8)           584       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 7, 7, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 7, 7, 8)           584       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 7, 7, 8)           0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 14, 14, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 14, 14, 8)         584       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 14, 14, 8)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 28, 28, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 28, 28, 16)        1168      \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 1)         145       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 4,385\n",
      "Trainable params: 4,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_2 (Sequential)    (None, 28, 28, 1)         4385      \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 10)                19092234  \n",
      "=================================================================\n",
      "Total params: 19,096,619\n",
      "Trainable params: 4,385\n",
      "Non-trainable params: 19,092,234\n",
      "_________________________________________________________________\n",
      "Epoch is 0\n",
      "Number of batches 600\n",
      "*** Generate Image by Auto encoder ***\n",
      "image_batch: (100, 28, 28, 1), generated_images:(100, 28, 28, 1)\n",
      "ylabel_train_batch: (100, 10), target_ylabel_train_batch:(100, 10)\n"
     ]
    }
   ],
   "source": [
    "train(BATCH_SIZE=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(BATCH_SIZE, nice=False):\n",
    "    g = auto_encoder_generator_model()\n",
    "    g_optim = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    g.compile(loss='binary_crossentropy', optimizer=g_optim)\n",
    "    g.load_weights('generator')\n",
    "    if nice:\n",
    "        d = discriminator_model()\n",
    "        d_optim = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "        d.compile(loss='binary_crossentropy', optimizer=g_optim)\n",
    "        d.load_weights('discriminator')\n",
    "\n",
    "        noise = np.random.uniform(-1, 1, (BATCH_SIZE*20, 100))\n",
    "        generated_images = g.predict(noise, verbose=1)\n",
    "        d_pret = d.predict(generated_images, verbose=1)\n",
    "        index  = np.arange(0, BATCH_SIZE*20)\n",
    "        index.resize((BATCH_SIZE*20, 1))\n",
    "        pre_with_index = list(np.append(d_pret, index, axis=1))\n",
    "        pre_with_index.sort(key=lambda x: x[0], reverse=True)\n",
    "        nice_images = np.zeros((BATCH_SIZE,) + generated_images.shape[1:3], dtype=np.float32)\n",
    "        nice_images = nice_images[:, :, :, None]\n",
    "\n",
    "        for i in range(BATCH_SIZE):\n",
    "            idx = int(pre_with_index[i][1])\n",
    "            nice_images[i, :, :, 0] = generated_images[idx, :, :, 0]\n",
    "        image = combine_images(nice_images)\n",
    "    else:\n",
    "        noise = np.random.uniform(-1, 1, (BATCH_SIZE, 100))\n",
    "        generated_images = g.predict(noise, verbose=1)\n",
    "        image = combine_images(generated_images)\n",
    "    image = image*127.5+127.5\n",
    "    Image.fromarray(image.astype(np.uint8)).save(\"generated_image.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(BATCH_SIZE=100, nice=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
